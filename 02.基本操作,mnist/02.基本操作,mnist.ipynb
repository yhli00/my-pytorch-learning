{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# 基本操作"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "import torch\n",
    "print(torch.__version__)\n",
    "print(torch.cuda.is_available())"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "1.8.0\n",
      "False\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 自动求导"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "from torch import autograd\n",
    "x = torch.tensor(7.)  # 默认requires_grad是False\n",
    "a = torch.tensor(999., requires_grad=True)\n",
    "b = torch.tensor(20., requires_grad=True)\n",
    "c = torch.tensor(30., requires_grad=True)\n",
    "y = a ** 2 * x + b * x + c\n",
    "grads = autograd.grad(y, [a, b, c])  # y函数对a,b,c求导\n",
    "print(grads[0], grads[1], grads[2])\n",
    "print(grads[0].item() == 7 * 999 * 2)\n",
    "print(grads[1].item() == 7)\n",
    "print(grads[2].item() == 1)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tensor(13986.) tensor(7.) tensor(1.)\n",
      "True\n",
      "True\n",
      "True\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# mnist"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import numpy as np\n",
    "from torch import optim"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "source": [
    "def loadData(filename):\n",
    "    x = []\n",
    "    y = []\n",
    "    with open(filename, 'r')as f:\n",
    "        for line in f.readlines():\n",
    "            cur_line = line.strip().split(',')\n",
    "            x.append([int(i) / 255 for i in cur_line[1:]])  # 归一化,不归一化训练时会出现loss=nan的情况\n",
    "            y.append(int(cur_line[0]))\n",
    "    return x, y\n",
    "\n",
    "def normalize(x):  # 归一化\n",
    "    for i in range(len(x)):\n",
    "        x[i] = [(j - min(x[i])) / (max(x[i]) - min(x[i])) for j in x[i]]\n",
    "\n",
    "class mnist_dataset(Dataset):\n",
    "    def __init__(self, x, y):\n",
    "        self.len = len(x)\n",
    "        self.x = np.array(x, dtype=np.float32)\n",
    "        self.y = np.array(y, dtype=np.float32)\n",
    "        self.x = torch.from_numpy(self.x)\n",
    "        self.y = torch.from_numpy(self.y)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.len\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.x[index], self.y[index]\n",
    "\n",
    "train_x , train_y = loadData('mnist/mnist_train.csv')\n",
    "test_x, test_y = loadData('mnist/mnist_test.csv')\n",
    "\n",
    "train_data = DataLoader(dataset=mnist_dataset(train_x, train_y), batch_size=512, shuffle=True)\n",
    "test_data = DataLoader(dataset=mnist_dataset(test_x, test_y), batch_size=512, shuffle=True)\n",
    "x_tmp, y_tmp = next(iter(train_data))\n",
    "print(f'数据shape:{x_tmp.shape}')\n",
    "print(f'数据集类型{x_tmp.dtype}')\n",
    "print(torch.min(x_tmp))\n",
    "print(torch.max(x_tmp))\n",
    "print(torch.max(y_tmp))\n",
    "print(torch.min(y_tmp))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "数据shape:torch.Size([512, 784])\n",
      "数据集类型torch.float32\n",
      "tensor(0.)\n",
      "tensor(1.)\n",
      "tensor(9.)\n",
      "tensor(0.)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(784, 256)\n",
    "        self.fc2 = nn.Linear(256, 64)\n",
    "        self.fc3 = nn.Linear(64, 10)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "net = Net()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.01, momentum=0.9)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "source": [
    "def one_hot(label):\n",
    "    label = label.long()\n",
    "    return torch.zeros(len(label), 10).scatter_(1, label.view(-1, 1), 1)\n",
    "label = torch.tensor([1., 2., 3., 5., 9.], dtype=torch.float32)\n",
    "print(one_hot(label))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tensor([[0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]])\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "source": [
    "for epoch in range(20):\n",
    "    for batch_idx, (x, y) in enumerate(train_data):\n",
    "        out = net(x)\n",
    "        loss = F.mse_loss(out, one_hot(y))\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if batch_idx % 50 == 0:\n",
    "            print(f'epoch[{epoch + 1}/{20}]:[{batch_idx}/{len(train_data)}]  loss={loss.item()}')"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "epoch[1/20]:[0/118]  loss=0.10734939575195312\n",
      "epoch[1/20]:[50/118]  loss=0.08664204925298691\n",
      "epoch[1/20]:[100/118]  loss=0.08042768388986588\n",
      "epoch[2/20]:[0/118]  loss=0.07889939844608307\n",
      "epoch[2/20]:[50/118]  loss=0.07275237888097763\n",
      "epoch[2/20]:[100/118]  loss=0.06787366420030594\n",
      "epoch[3/20]:[0/118]  loss=0.06601966917514801\n",
      "epoch[3/20]:[50/118]  loss=0.06129629164934158\n",
      "epoch[3/20]:[100/118]  loss=0.05830339714884758\n",
      "epoch[4/20]:[0/118]  loss=0.056342411786317825\n",
      "epoch[4/20]:[50/118]  loss=0.05209506303071976\n",
      "epoch[4/20]:[100/118]  loss=0.05069391801953316\n",
      "epoch[5/20]:[0/118]  loss=0.049439746886491776\n",
      "epoch[5/20]:[50/118]  loss=0.047182101756334305\n",
      "epoch[5/20]:[100/118]  loss=0.04756007343530655\n",
      "epoch[6/20]:[0/118]  loss=0.04524365812540054\n",
      "epoch[6/20]:[50/118]  loss=0.04342168942093849\n",
      "epoch[6/20]:[100/118]  loss=0.042544059455394745\n",
      "epoch[7/20]:[0/118]  loss=0.04335609823465347\n",
      "epoch[7/20]:[50/118]  loss=0.041015900671482086\n",
      "epoch[7/20]:[100/118]  loss=0.040989089757204056\n",
      "epoch[8/20]:[0/118]  loss=0.041295211762189865\n",
      "epoch[8/20]:[50/118]  loss=0.03913778439164162\n",
      "epoch[8/20]:[100/118]  loss=0.038380369544029236\n",
      "epoch[9/20]:[0/118]  loss=0.040269624441862106\n",
      "epoch[9/20]:[50/118]  loss=0.03480672836303711\n",
      "epoch[9/20]:[100/118]  loss=0.034992557018995285\n",
      "epoch[10/20]:[0/118]  loss=0.033246878534555435\n",
      "epoch[10/20]:[50/118]  loss=0.03594779968261719\n",
      "epoch[10/20]:[100/118]  loss=0.032539691776037216\n",
      "epoch[11/20]:[0/118]  loss=0.032692380249500275\n",
      "epoch[11/20]:[50/118]  loss=0.03480956703424454\n",
      "epoch[11/20]:[100/118]  loss=0.032453615218400955\n",
      "epoch[12/20]:[0/118]  loss=0.03096984699368477\n",
      "epoch[12/20]:[50/118]  loss=0.030510246753692627\n",
      "epoch[12/20]:[100/118]  loss=0.030745234340429306\n",
      "epoch[13/20]:[0/118]  loss=0.03031853958964348\n",
      "epoch[13/20]:[50/118]  loss=0.030748462304472923\n",
      "epoch[13/20]:[100/118]  loss=0.031254254281520844\n",
      "epoch[14/20]:[0/118]  loss=0.02855745516717434\n",
      "epoch[14/20]:[50/118]  loss=0.030411070212721825\n",
      "epoch[14/20]:[100/118]  loss=0.02932298742234707\n",
      "epoch[15/20]:[0/118]  loss=0.02954208478331566\n",
      "epoch[15/20]:[50/118]  loss=0.0262615829706192\n",
      "epoch[15/20]:[100/118]  loss=0.030092883855104446\n",
      "epoch[16/20]:[0/118]  loss=0.02760854735970497\n",
      "epoch[16/20]:[50/118]  loss=0.028188902884721756\n",
      "epoch[16/20]:[100/118]  loss=0.026770377531647682\n",
      "epoch[17/20]:[0/118]  loss=0.026363898068666458\n",
      "epoch[17/20]:[50/118]  loss=0.027900423854589462\n",
      "epoch[17/20]:[100/118]  loss=0.025879502296447754\n",
      "epoch[18/20]:[0/118]  loss=0.02460954710841179\n",
      "epoch[18/20]:[50/118]  loss=0.0273190438747406\n",
      "epoch[18/20]:[100/118]  loss=0.026355277746915817\n",
      "epoch[19/20]:[0/118]  loss=0.02332361973822117\n",
      "epoch[19/20]:[50/118]  loss=0.023529689759016037\n",
      "epoch[19/20]:[100/118]  loss=0.025228897109627724\n",
      "epoch[20/20]:[0/118]  loss=0.02446998655796051\n",
      "epoch[20/20]:[50/118]  loss=0.020913314074277878\n",
      "epoch[20/20]:[100/118]  loss=0.024387633427977562\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "source": [
    "total = 0\n",
    "correct_num = 0\n",
    "with torch.no_grad():\n",
    "    for x, y in test_data:\n",
    "        total += len(x)\n",
    "        out = net(x)\n",
    "        out = torch.argmax(out, dim=1)\n",
    "        correct_num += out.eq(y).sum().float()\n",
    "print(f'acc={correct_num / total}')"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "acc=0.9136999845504761\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.8",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.8 64-bit (conda)"
  },
  "interpreter": {
   "hash": "15a4ac218c62ce2dce145f1061d459e77596cd4eab36502bfa13ffde77b805c2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}