{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# 基本数据类型\n",
    "+ torch.float32(torch.float)\n",
    "+ torch.float64(torch.double)\n",
    "+ torch.int32(torch.int)\n",
    "+ torch.int64(torch.long)\n",
    "+ torch.bool"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import torch\n",
    "a = torch.tensor([1, 2, 3], dtype=torch.long)\n",
    "print(a, a.dtype)\n",
    "a = torch.tensor([1, 2, 3], dtype=torch.float)\n",
    "print(a, a.dtype)\n",
    "a = torch.tensor([1, 2, 3], dtype=torch.bool)\n",
    "print(a, a.dtype)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tensor([1, 2, 3]) torch.int64\n",
      "tensor([1., 2., 3.]) torch.float32\n",
      "tensor([True, True, True]) torch.bool\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "`torch.rand`生成[0, 1)之间的均匀分布  \n",
    "`torch.randn`生成标准正态分布"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "a = torch.rand(2, 3)\n",
    "b = torch.randn(3, 1)\n",
    "print(a)\n",
    "print(a.shape)\n",
    "print(b)\n",
    "print(b.shape)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tensor([[0.2509, 0.9394, 0.2846],\n",
      "        [0.3122, 0.4418, 0.0227]])\n",
      "torch.Size([2, 3])\n",
      "tensor([[ 0.6012],\n",
      "        [-0.1440],\n",
      "        [ 0.4867]])\n",
      "torch.Size([3, 1])\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 创建tensor \n",
    "`torch.from_numpy(ndarray)`是浅拷贝  \n",
    "`torch.as_tensor(data, dtype=None, device=None)`:  \n",
    "+ 如果data已经是tensor且dtype和device与参数相同，则创建的tensor与data共享内存\n",
    "+ 如果data是narray，且dtype对应，device是cpu，则创建的tensor与data共享内存\n",
    "+ 否则是深拷贝"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "import numpy as np\n",
    "a = np.array([1, 2, 3])\n",
    "b = torch.from_numpy(a)\n",
    "print(a)\n",
    "a = np.array([1, 2, 3])\n",
    "b = torch.as_tensor(a, device=torch.device('cpu'))\n",
    "print(a)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[1 2 3]\n",
      "[1 2 3]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "直接创建  \n",
    "`torch.Tensor`==`torch.FloatTensor`  \n",
    "**注意：**\n",
    "+ `torch.tensor(4)`创建一个值为4的标量tensor\n",
    "+ `torch.Tensor(4)`创建长度为4，每个值是0.0的1维tensor"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "source": [
    "a = torch.Tensor([[1, 2], [3, 4]])\n",
    "b = torch.FloatTensor([[1, 2], [3, 4]])\n",
    "print(a.dtype)\n",
    "print(b.dtype)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "torch.float32\n",
      "torch.float32\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "`torch.tensor(data, dtype=None, device=None, requires_grad=False) `是对data的深拷贝  \n",
    "+ 如果只是想改变一个Tensor数据的`requires_grad`标志，使用`requires_grad_()`或者`detach()`来避免深拷贝  \n",
    "+ 当x是tensor时`torch.tensor(x)` == `x.clone().detach()`\n",
    "+ `torch.tensor(x, reauires_grad=True)` == `x.clone().detach().requires_grad_(True)`"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "source": [
    "a = torch.tensor([1, 2, 3], dtype=torch.float)\n",
    "print(a)\n",
    "b = a.clone().detach()  # 等价于torch.tensor(a)\n",
    "print(b)\n",
    "b[0] = -1\n",
    "print(a)\n",
    "print(b)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tensor([1., 2., 3.])\n",
      "tensor([1., 2., 3.])\n",
      "tensor([1., 2., 3.])\n",
      "tensor([-1.,  2.,  3.])\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "`torch.full`  \n",
    "`torch.full(size, full_value)`返回值的dtype由full_value的值决定"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "a = torch.full((2, 3), 7)\n",
    "b = torch.full((2, 3), 7.7)\n",
    "print(a.dtype)\n",
    "print(b.dtype)\n",
    "print(b)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "torch.int64\n",
      "torch.float32\n",
      "tensor([[7.7000, 7.7000, 7.7000],\n",
      "        [7.7000, 7.7000, 7.7000]])\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "`torch.arange`"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "source": [
    "a = torch.arange(1, 5)\n",
    "b = torch.arange(1, 5, step=1.5)\n",
    "print(a, a.dtype)\n",
    "print(b, b.dtype)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tensor([1, 2, 3, 4]) torch.int64\n",
      "tensor([1.0000, 2.5000, 4.0000]) torch.float32\n"
     ]
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.8",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.8 64-bit (conda)"
  },
  "interpreter": {
   "hash": "15a4ac218c62ce2dce145f1061d459e77596cd4eab36502bfa13ffde77b805c2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}