{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# view/reshape\n",
    "## view  \n",
    "**view操作要求tensor在内存中是连续存储的**，在进行了transpose、permute操作之后tensor不连续，需要使用contiguous得到一个连续的copy，之后再进view操作  \n",
    "## reshape\n",
    "**reshape函数相当于tensor.contiguous().view()**，省去了对tensor进行view操作前的contiguous操作"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "import torch\n",
    "a = torch.rand(3, 4)\n",
    "b = a.transpose(0, 1)\n",
    "b.is_contiguous()  # False\n",
    "print(a.reshape(2, 6))\n",
    "print(a.view(2, 6))\n",
    "print(b.reshape(2, 6))\n",
    "print(b.contiguous().view(2, 6))\n",
    "# print(b.view(2, 6))报错"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tensor([[0.8238, 0.2714, 0.1760, 0.6312, 0.7975, 0.4702],\n",
      "        [0.7563, 0.7784, 0.5535, 0.7110, 0.6299, 0.8340]])\n",
      "tensor([[0.8238, 0.2714, 0.1760, 0.6312, 0.7975, 0.4702],\n",
      "        [0.7563, 0.7784, 0.5535, 0.7110, 0.6299, 0.8340]])\n",
      "tensor([[0.8238, 0.7975, 0.5535, 0.2714, 0.4702, 0.7110],\n",
      "        [0.1760, 0.7563, 0.6299, 0.6312, 0.7784, 0.8340]])\n",
      "tensor([[0.8238, 0.7975, 0.5535, 0.2714, 0.4702, 0.7110],\n",
      "        [0.1760, 0.7563, 0.6299, 0.6312, 0.7784, 0.8340]])\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# unsqueeze/squeeze\n",
    "## unsqueeze\n",
    "+ **作用**：维度扩展\n",
    "+ **注意**：返回的tensor和输入的tensor共享内存，改变其中一个的内容会改变另一个  \n",
    "## squeeze\n",
    "+ **作用**：维度压缩，比如输入tensor的形状是$A\\times 1\\times B\\times 1\\times C$，返回的tensor形状是$A\\times B\\times C$，当给定dim时，挤压操作只会发生在指定的dim上\n",
    "+ **注意**：返回的tensor和输入的tensor共享内存，改变其中一个的内容会改变另一个"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "import torch\n",
    "a = torch.rand(1, 3, 1, 4)\n",
    "print(a.squeeze().shape)\n",
    "print(a.squeeze(dim=0).shape)\n",
    "print(a.unsqueeze(dim=4).shape)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "torch.Size([3, 4])\n",
      "torch.Size([3, 1, 4])\n",
      "torch.Size([1, 3, 1, 4, 1])\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# expand/repeat\n",
    "## Tensor.expand(*size)->Tensor\n",
    "+ **作用**：扩展tensor，size的维度要等于原tensor维度\n",
    "+ **注意**：**浅拷贝，只能扩展维度为1的那一维**，当传入参数为-1时那一维不做扩展  \n",
    "## Tensor.repeat(*size)->Tensor\n",
    "+ **作用**：扩展tensor，size的维度要大于等于原tensor维度，size[i]表示把对应tensor的维度扩展为**多少倍**\n",
    "+ **注意**：**深拷贝**"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "a = torch.tensor([[1, 2, 3]])\n",
    "print(a.expand(3, -1))\n",
    "print(a.expand(3, 3))  # 等价与上面一条\n",
    "print(a.repeat(3, 1))\n",
    "print(a.repeat(2, 3, 2).shape)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tensor([[1, 2, 3],\n",
      "        [1, 2, 3],\n",
      "        [1, 2, 3]])\n",
      "tensor([[1, 2, 3],\n",
      "        [1, 2, 3],\n",
      "        [1, 2, 3]])\n",
      "tensor([[1, 2, 3],\n",
      "        [1, 2, 3],\n",
      "        [1, 2, 3]])\n",
      "torch.Size([2, 3, 6])\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# transpose/permute\n",
    "## Tensor.transpose(dim0, dim1) → Tensor\n",
    "+ **作用**：交换两个维度\n",
    "+ **注意**：浅拷贝，会使原来contiguous的tensor变得不contiguous  \n",
    "## Tensor.permute(*dims) → Tensor\n",
    "+ **作用**：交换tensor的维度，dim的维度等于原tensor的维度大小，dim[0]表示变换后的tensor的第一维是原tensor的第几维\n",
    "+ **注意**：浅拷贝，会使原来contiguous的tensor变得不contiguous\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "a = torch.rand(2, 3, 4)\n",
    "b = a.transpose(1, 2)\n",
    "c = a.permute(2, 1, 0)\n",
    "print(b.shape)\n",
    "print(c.shape)\n",
    "print(b.is_contiguous())"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "torch.Size([2, 4, 3])\n",
      "torch.Size([4, 3, 2])\n",
      "False\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.8",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.8 64-bit (conda)"
  },
  "interpreter": {
   "hash": "15a4ac218c62ce2dce145f1061d459e77596cd4eab36502bfa13ffde77b805c2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}